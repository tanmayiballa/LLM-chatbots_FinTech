{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A bot using LLM and Neo4j "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample notebook to generate Cypher queries and create text responses.\n",
    "\n",
    "##### User Query -> LLM (to generate cypher) -> Query Neo4j KG -> LLM (to generate response using the KG result).\n",
    "\n",
    "##### Author: Tanmayi Balla(tballa@iu.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import timeout_decorator\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import secret\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import CypherSyntaxError\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = secret.openai_api_key # \"<Your API-KEY>\"\n",
    "#model = \"gpt-4\" # \"gpt-3.5-turbo\"\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url=\"neo4j+s://88f69104.databases.neo4j.io\"\n",
    "#user=\"neo4j\"\n",
    "#password=\"\"\n",
    "url = \"neo4j+s://linguistic.technology:7687\"\n",
    "user = \"l715\"\n",
    "password = \"frozen-sharp-darwin-sponsor-weekend-6115\"\n",
    "\n",
    "driver = GraphDatabase.driver(url, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_properties_query = \"\"\"\n",
    "call db.schema.nodeTypeProperties() yield nodeLabels,propertyName \n",
    "WITH nodeLabels AS nodeLabels, collect(propertyName) AS properties\n",
    "RETURN {labels: nodeLabels, properties: properties} AS output\n",
    "\"\"\"\n",
    "\n",
    "rel_properties_query = \"\"\"\n",
    "call db.schema.relTypeProperties() yield relType,propertyName \n",
    "WITH relType AS relType, collect(propertyName) AS properties\n",
    "RETURN {labels: relType, properties: properties} AS output\n",
    "\"\"\"\n",
    "\n",
    "rel_query = \"\"\"\n",
    "MATCH (first)-[r]->(second)\n",
    "RETURN DISTINCT {source:head(labels(first)),\n",
    "       relationship:type(r),\n",
    "       target:head(labels(second))} AS output\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_neo4j_db(cypher_query, params={}):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(cypher_query, params)\n",
    "        output = [r.values() for r in result]\n",
    "        output.insert(0, result.keys())\n",
    "        return output\n",
    "\n",
    "def schema_text(node_props, rel_props, rels):\n",
    "    return f\"\"\"\n",
    "  This is the schema representation of the Neo4j database.\n",
    "  Node properties are the following:\n",
    "  {node_props}\n",
    "  Relationship properties are the following:\n",
    "  {rel_props}\n",
    "  Relationship point from source to target nodes\n",
    "  {rels}\n",
    "  Make sure to respect relationship types and directions\n",
    "  \"\"\"\n",
    "\n",
    "def generate_schema():\n",
    "    node_props = query_neo4j_db(node_properties_query)\n",
    "    rel_props = query_neo4j_db(rel_properties_query)\n",
    "    rels = query_neo4j_db(rel_query)\n",
    "    return schema_text(node_props, rel_props, rels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = generate_schema()\n",
    "\n",
    "def create_cypher(query, history = None):\n",
    "    \n",
    "    sys_message = f\"\"\"\n",
    "        Task: Generate Cypher queries to query a Neo4j graph database based on the provided schema definition.\n",
    "        Instructions:\n",
    "        Use only the provided relationship types and properties.\n",
    "        Do not use any other relationship types or properties that are not provided.\n",
    "        Note: Do not include any explanations or apologies in your responses.\n",
    "        If you cannot generate a Cypher statement based on the provided schema, explain the reason to the user.\n",
    "        Schema:\n",
    "        {schema}\n",
    "\n",
    "        Note: Do not include any explanations or apologies in your responses.\n",
    "        \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_message},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    if history:\n",
    "        messages.extend(history)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1000,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(query, history = None, retry = True):\n",
    "    cypher = create_cypher(query)\n",
    "    print(cypher)\n",
    "    try:\n",
    "        return query_neo4j_db(cypher)\n",
    "    except CypherSyntaxError as e:\n",
    "        if not retry:\n",
    "          return \"Invalid Cypher syntax\"\n",
    "        print(\"Retrying\")\n",
    "        return run_pipeline(\n",
    "            query,\n",
    "            [\n",
    "                {\"role\": \"assistant\", \"content\": cypher},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"This query returns an error: {str(e)} \n",
    "                    Give me a improved query that works without any explanations or apologies\"\"\",\n",
    "                },\n",
    "            ],\n",
    "            retry=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (c:Corporation {name: 'Apple Inc.'})-[:INCORPORATED_IN]->(s:State)\n",
      "RETURN s.name as location\n"
     ]
    }
   ],
   "source": [
    "sample_res = run_pipeline(\"\"\"\n",
    "In which location is Apple Inc. incorporated?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (c:Corporation)\n",
      "WHERE c.name IN ['Apple Inc.', 'ELI LILLY & Co', 'BRISTOL MYERS SQUIBB CO', 'Samsung']\n",
      "MATCH (c)-[:INCORPORATED_IN]->(s:State)\n",
      "RETURN c.name AS Company, s.name AS Headquarters\n"
     ]
    }
   ],
   "source": [
    "sample_res = run_pipeline(\"\"\"\n",
    "What are the headquarters of the companies: Apple Inc., ELI LILLY & Co, BRISTOL MYERS SQUIBB CO, and Samsung?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Company', 'Headquarters'],\n",
       " ['ELI LILLY & Co', 'Indiana'],\n",
       " ['BRISTOL MYERS SQUIBB CO', 'Delaware'],\n",
       " ['Apple Inc.', 'California']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['location'], ['California']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (o:Organization)-[:Partnered_with]->(p:Organization {name: 'Rocket Lab'}) \n",
      "RETURN o.name\n"
     ]
    }
   ],
   "source": [
    "sample_res = run_pipeline(\"\"\"\n",
    "Which organizations partnered with Rocket Lab?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['o.name'], ['Silicon Valley Bank'], ['Hercules Capital, Inc.']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_dbtotext = f\"\"\"\n",
    "# You are an assistant that helps to generate text to form nice and human understandable answers based.\n",
    "# The latest prompt contains the information, and you need to generate a human readable response based on the given information.\n",
    "# Make it sound like the information are coming from an AI assistant, but don't add any information.\n",
    "# Do not add any additional information that is not explicitly provided in the latest prompt.\n",
    "# I repeat, do not add any information that is not explicitly given.\n",
    "# \"\"\"\n",
    "\n",
    "system_dbtotext = f\"\"\"\n",
    "You are an assistant that helps to generate text to form nice and human understandable answers based.\n",
    "The latest prompt contains the results retrieved from the database, and you need to generate a human readable response using only the results.\n",
    "Make it sound like the information are coming from an AI assistant, but don't add any information.\n",
    "If the results retrived are not related to the user query, they simple say that you don't know the answer and the results doesn't match with the same.\n",
    "Do not add any additional information that is not explicitly provided in the latest prompt.\n",
    "I repeat, do not add any information that is not explicitly given.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_response(query, data):\n",
    "    prompt = \"User query: \" + str(query) + \"Graph database result: \" + str(data)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_dbtotext},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ] \n",
    "\n",
    "    completions = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    response = completions.choices[0].message.content\n",
    "    # If the model apologized, remove the first line or sentence\n",
    "    if \"apologi\" in response:\n",
    "        if \"\\n\" in response:\n",
    "            response = \" \".join(response.split(\"\\n\")[1:])\n",
    "        else:\n",
    "            response = \" \".join(response.split(\".\")[1:])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. is incorporated in California.\n"
     ]
    }
   ],
   "source": [
    "query = \"In which location is Apple Inc. incorporated?\"\n",
    "data = sample_res[1:]\n",
    "print(generate_response(query, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The headquarters of the companies you mentioned are as follows: ELI LILLY & Co is headquartered in Indiana, BRISTOL MYERS SQUIBB CO is headquartered in Delaware, and Apple Inc. is headquartered in California. Unfortunately, I don't have information about the headquarters of Samsung.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the headquarters of the companies: Apple Inc., ELI LILLY & Co, BRISTOL MYERS SQUIBB CO, and Samsung?\"\n",
    "data = sample_res[1:]\n",
    "print(generate_response(query, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rocket Lab has partnered with two organizations: Silicon Valley Bank and Hercules Capital, Inc.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which organizations partnered with Rocket Lab?\"\n",
    "data = sample_res[1:]\n",
    "print(generate_response(query, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I couldn't find any relevant information about the invention of the telephone in the graph database. It seems that the results retrieved are not related to your query.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who invented telephone?\"\n",
    "data = sample_res[1:]\n",
    "print(generate_response(query, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
